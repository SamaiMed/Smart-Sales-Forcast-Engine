{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(800, 900) \n",
      "Test set: \t\t(200, 900)\n",
      "label set: \t\t(800,) \n",
      "Test label set: \t\t(200,)\n"
     ]
    }
   ],
   "source": [
    "with open('lab.txt', 'r') as f:\n",
    "    labels_org = f.read()\n",
    "df=pd.read_csv('Seq_Embo_f.csv',header=None)\n",
    "features=np.array(df[:][:]).astype(np.float32)\n",
    "labels = np.array([int(_)  for _ in labels_org.split()]).astype(np.int64)+1\n",
    "#labels =np.array([int(_)  for _ in labels_org.split()]).astype(np.floa32))\n",
    "train_x,test_x,train_y,test_y=train_test_split(features,labels,test_size=0.2)\n",
    "#train_x=train_x.reshape(-1,30,30)\n",
    "#test_x=test_x.reshape(-1,30,30)\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
    "print(\"label set: \\t\\t{}\".format(train_y.shape), \"\\nTest label set: \\t\\t{}\".format(test_y.shape))\n",
    "def get_batches(x, y, batch_size=800):\n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len=30\n",
    "embeding_size=30\n",
    "n_input = embeding_size*seq_len\n",
    "n_classes = 3\n",
    "learning_rate = 0.01\n",
    "training_iters = 200000\n",
    "batch_size = 800\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "keep_prob = tf.placeholder(tf.float32) \n",
    "dropout=1\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    global embeding_size\n",
    "    global seq_len\n",
    "    x = tf.reshape(x, shape=[-1, embeding_size, seq_len, 1])\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 6])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 6, 12])),\n",
    "    'wd1': tf.Variable(tf.random_normal([30*30*12, 150])),\n",
    "    'out': tf.Variable(tf.random_normal([150, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([6])),\n",
    "    'bc2': tf.Variable(tf.random_normal([12])),\n",
    "    'bd1': tf.Variable(tf.random_normal([150])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "soft_a=tf.nn.softmax(pred)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(cost)\n",
    "correct_pred = tf.equal(tf.argmax(soft_a, 1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0 Train accuracy: 0.42375 Test accuracy: 0.62 F1: 0.62\n",
      "1 Train accuracy: 0.60125 Test accuracy: 0.185 F1: 0.185\n",
      "2 Train accuracy: 0.1775 Test accuracy: 0.265 F1: 0.265\n",
      "3 Train accuracy: 0.24875 Test accuracy: 0.64 F1: 0.64\n",
      "4 Train accuracy: 0.635 Test accuracy: 0.64 F1: 0.64\n",
      "5 Train accuracy: 0.635 Test accuracy: 0.64 F1: 0.64\n",
      "6 Train accuracy: 0.635 Test accuracy: 0.64 F1: 0.64\n",
      "7 Train accuracy: 0.635 Test accuracy: 0.64 F1: 0.64\n",
      "8 Train accuracy: 0.63875 Test accuracy: 0.55 F1: 0.55\n",
      "9 Train accuracy: 0.56375 Test accuracy: 0.3 F1: 0.3\n"
     ]
    }
   ],
   "source": [
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('Initialized')\n",
    "    for epoch in range(10):\n",
    "        for io,(xx,yy) in enumerate(get_batches(train_x, train_y, 800), 1):\n",
    "            X_batch  = xx\n",
    "            y_batch  = yy\n",
    "            _,acc_train=sess.run([training_op, accuracy],feed_dict={x: X_batch, y: y_batch,keep_prob: 1})\n",
    "        acc_test = accuracy.eval(feed_dict={x: test_x, y: test_y, keep_prob: 1})\n",
    "        temp=soft_a.eval(feed_dict={x: test_x, y: test_y, keep_prob: 1})\n",
    "        temp0=np.argmax(temp,axis=1)\n",
    "        temp1=sk.metrics.f1_score(test_y.reshape(-1),temp0,average='micro')\n",
    "        print(epoch, \"Train accuracy:\",acc_train , \"Test accuracy:\", acc_test,'F1:',temp1)\n",
    "        saver.save(sess, \"checkpoints/sento-anal_f1_CNN_enbedno_0.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1, -1,  1,  1,  0, -1,  0,  0, -1,  1, -1, -1,  1,  0,\n",
       "        0, -1, -1, -1,  0, -1,  0, -1, -1,  2,  0,  0,  1,  0,  0,  0,  0,\n",
       "        0,  1, -1,  0, -1,  0, -1, -1, -1,  1,  1, -1, -1,  0, -1, -1,  0,\n",
       "        0,  2, -1,  0,  2,  1,  0,  1, -1,  0,  1, -1,  1,  1, -1, -1,  2,\n",
       "        0,  0,  0,  1,  2,  0, -1,  0,  0,  0, -1,  0,  0, -1, -1,  0,  1,\n",
       "       -1,  0,  1, -1,  0, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0, -1,  0,\n",
       "       -1,  0, -1,  0,  0,  0,  0, -1,  0,  1, -1,  1, -1,  0,  0, -1,  0,\n",
       "        0,  0, -1,  0,  1,  0, -1,  0,  1,  0, -1,  0, -1, -1, -1,  1, -1,\n",
       "       -1,  1, -1, -1, -1,  0, -1, -1, -1, -1, -1,  0,  2, -1, -1,  0, -1,\n",
       "        0, -1, -1,  1, -1,  1,  0,  0, -1,  2,  0, -1, -1, -1,  0,  1,  0,\n",
       "       -1, -1, -1,  0,  0,  1, -1,  1, -1, -1, -1, -1, -1,  0, -1, -1,  0,\n",
       "       -1,  0, -1,  2, -1, -1,  0, -1, -1,  1, -1,  0, -1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp0-test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
